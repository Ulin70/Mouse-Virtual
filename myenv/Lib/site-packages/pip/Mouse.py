import cv2
import glob
import cv2 as cv
import numpy as np
import mediapipe as mp
import pyautogui as pg
import cv2.aruco as aruco

class GestureController:
    def __init__(self, dict_type):
        self.aruco_dict = aruco.Dictionary_get(dict_type) # type: ignore
        # Lanjutkan dengan inisialisasi lainnya

# Initialize the webcam
cam = cv.VideoCapture(0)

if not cam.isOpened():
    print("Error: Could not open webcam.")
    exit()

# Initialize Mediapipe hands module
mphands = mp.solutions.hands # type: ignore
hands = mphands.Hands()
mpDraw = mp.solutions.drawing_utils # type: ignore

# Get screen dimensions
screenWidth, screenHeight = pg.size()
print(f"Screen dimensions: {screenWidth}x{screenHeight}")

# Frame reduction for better performance
frameR = 100

# Tip IDs for each finger
tipid = [4, 8, 12, 16, 20]

# Click state
clk = 1

while True:
    success, img = cam.read()
    if not success:
        print("Error: Failed to capture image.")
        break

    img = cv.flip(img, 1)
    h, w, c = img.shape

    imgRGB = cv.cvtColor(img, cv.COLOR_BGR2RGB)
    results = hands.process(imgRGB)

    # Draw a rectangle for the frame reduction area
    cv.rectangle(img, (frameR, frameR), (w - frameR, h - frameR), (255, 0, 0), 2)

    if results.multi_hand_landmarks:
        hand_label = results.multi_handedness[0].classification[0].label
        if hand_label == "Right":
            lmlist = []

            for handLms in results.multi_hand_landmarks:
                for id, landmarks in enumerate(handLms.landmark):
                    cx, cy = int(landmarks.x * w), int(landmarks.y * h)
                    lmlist.append([id, cx, cy])

            if len(lmlist) == 21:  # Ensure all landmarks are detected
                fingers = []
                # Thumb
                if lmlist[tipid[0]][1] < lmlist[tipid[0] - 2][1]:
                    fingers.append(1)
                else:
                    fingers.append(0)

                # Other fingers
                for id in range(1, 5):
                    if lmlist[tipid[id]][2] < lmlist[tipid[id] - 3][2]:
                        fingers.append(1)
                    else:
                        fingers.append(0)

                # Check for specific gesture
                if fingers == [0, 1, 1, 0, 0]:
                    cv.circle(img, (lmlist[12][1], lmlist[12][2]), 10, (0, 0, 255), cv.FILLED)

                    X = np.interp(lmlist[12][1], (frameR, w - frameR), (0, screenWidth))
                    Y = np.interp(lmlist[12][2], (frameR, h - frameR), (0, screenHeight))

                    length = abs(lmlist[8][1] - lmlist[12][1])

                    pg.moveTo(X, Y, duration=0)  # Set duration to 0 for instant movement

                    if (lmlist[8][2] > lmlist[7][2]) and clk > 0:
                        pg.click()
                        clk = -1
                    elif (lmlist[8][2] < lmlist[7][2]):
                        clk = 1

                    if length > 50:
                        pg.scroll(100)
                    else:
                        pg.scroll(-100)

    cv.imshow("webcam", img)

    if cv.waitKey(20) & 0xFF == ord('d'):
        break

cam.release()
cv.destroyAllWindows()
